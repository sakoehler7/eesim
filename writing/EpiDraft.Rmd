---
title: "Outstanding Title"
author: "Sarah Koehler"
date: "February 21, 2017"
bibliography: mybibfile.bib
output:
  pdf_document: default
  html_document: default
---

#Introduction

Simulation studies are important in environmental epidemiology research on air pollution, temperature, and other exposures. For example, simulated data can be used to test new statistical models and perform power analyses. Two current challenges of simulating time series data for epidemiology studies are (1) methods for simulating are inconsistent, making it difficult to compare results from different studies, and (2) developing the code to simulate environmental time series for these types of studies can be time consuming. We introduce `eesim`, an open-source software package in R that offers a solution to these challenges.

Simulated data has been used in a number of environmental epidemiology studies on various kinds of exposures and outcomes. [@Armstrong2014] used a simulation study to investigate short-term mortality displacement following heat waves. [@Bateson1999], [@Bateson2001], and [@Peng2006] used simulated data with confounding seasonal trends to compare experimental designs and model choice. [@Strickland2015], [@Gryparis2009], and [@Butland2013] investigated spatial misalignment and geographic heterogeneity of exposures using simulated data. [@Roberts2006] used a simulation study to test the reliability of using AIC to determine the shape of the relationship between particulate matter and mortality. [@Bobb2015] used simulation to assess the performance of a proposed method for estimating the health effects of multi-pollutant exposures called Bayesian kernel machine regression (BKMR). 

Here, we present an R package that automates simulation of environmental time series for such studies, offering both sensible defaults for each stage of the simulation process and also the option to customize any of the simulation steps while using defaults for any steps that do not require customization. There are a few important advantages to having an open-source software package that can simulate this type of environmental time series for simulation studies. This package offers several methods of simulating time series so researchers can check if study results are robust to the data simulation method [@Alfons2010]. This software also allows for consistency and comparison of data simulation across studies and will save researchers time and effort in developing study-specific code. 

This package can be used to aid simulation studies to explore environmental epidemiology models relating acute health outcomes and daily environmental exposures; it can also be used to estimate the power of studies when planning or proposing future research.

#Simulating Data and Testing Models

Simulation studies can be used to assess different models and modeling choices. This way of assessing models can be particularly useful for complex statistical methods, for which assessing performance metrics can often prove difficult [@Alfons2010]. The `eesim` package allows you to simulate time series of environmental health data and perform simulation-based power analyses and other measures of model performance. The package includes four main parts: 

1. Generation of exposure data; 
2. Generation of outcome data;
3. Fitting models to simulated data; and 
4. Evaluating model performance on simulated data.

The user has the option to customize different aspects of the simulation at each of these steps.

The main function of this package is the `eesim` function. You can use the `eesim` function to conduct all four steps of the simulation process outlined above at once. The `eesim` function requires several arguments, both numeric and character, including the desired number of repetitions of the simulation, the sample size for each repetiton, the type of exposure values (binary or continous), the expected average value of the response variable, the relative risk, and the type of model desired. The user has the option to input more arguments specifying trends or custom functions for the exposure, the outcome, or both.

The `eesim` function returns a list with two elements. The first element gives simulation-specific results: the estimated effect size, standard error, t- and p-values, and upper and lower 95% confidence bounds when a model was applied to each set of simulated data. The second element gives some measures of model assessment, assessed over all simulations, including the mean effect size and relative risk estimates across simulations.

[insert equation here?]

For example, you can use the following call to (1) generate 3 repetitions of 100 observations of a continuous exposure with mean 50 and standard deviation 5, with a seasonal trend in expected value; (2) generate 10 associated outcome values, where the outcome has an average value of 20 and a relative risk of 1.10 per one-unit increase in the exposure; (3) fit a generalized linear model that controls for long-term and seasonal trends with a natural cubic spline with 2 degrees of freedom per year; and (4) evaluate the performace of that model on the simulated data:

```{r}
library(eesim)
eesim(n_reps = 3, n = 100, central = 50, sd = 5, outcome_amp = .6, exposure_type = "continuous", outcome_trend = "cos1", average_outcome = 20, rr = 1.10, model = "spline", df_year = 2)
```

The above output gives the estimated effect sizes for each of the three repetitions along with their standard errors, test statistics, p-values, and confidence intervals. It also summarizes the outcomes of all three repetitions with a mean estimated beta (which equals the log of the estimated relative risk), estimated relative risk, the variance of the estimated betas, and the mean variance of the individual betas.  

The `eesim` output also gives the relative parameter estimate bias, according to the following equation  from [@Beaujean2014], given $\theta_{H}$ (true value of the parameter, as set when creating the simulated data) and $\hat{\theta}$ (value of the parameter estimated from applying a model to the simulated data): 

\begin{equation}
\theta_{bias} = \frac{\hat{\theta} - \theta_{H}}{\theta_{H}}
\end{equation}

Finally, the `eesim` output gives the coverage and power of the model.

#Power Analysis

Simulation studies can be used to determine effective sample size or power when planning or proposing future research studies. This method can be particularly useful in cases where modeling of the study data will be particularly complex and when the strong assumptions of classical, analytical power analysis are questionable [@Bellan2015; @Johnson2015; @Burton2009; @Alfons2010; @Beaujean2014; @Schoemann2014]. Simulation studies can often be used to generate power analyses under a more realistic set of assumptions [@Burton2009; @Beaujean2014].

In `eesim`, the function `power_calc` can be used to investigate the effects of various sample sizes or relative risks on power. This function requires arguments including the parameter to be varied (sample size or relative risk), the desired values of that parameter, and lists of the same arguments as used in the `eesim` function. The `power_calc` function outputs a table of the values of the varied parameter along with their corresponding power. 
Here is an example of using `power_calc` to test power for different sample sizes:

```{r}
#Power_calc momentarily out of commission :(
```

The `power_calc` function will also return a plot if `plot=TRUE` is specified. 

##Legionnaire's Example

###Actual Data from the CDC

Here is a plot of weekly counts of Legionnaire's disease in the United States from 2014 through 2016. This data was obtained from the CDC website.

```{r, echo=FALSE}
#I used the variable "Legionellosis, Current week" so hopefully that's right
leg1 <- read.csv("~/eesim/Legionnaires data/2014Leg.csv")[,c(2,3,24)]
leg2 <- read.csv("~/eesim/Legionnaires data/2015Leg.csv")[,c(2,3,24)]
leg3 <- read.csv("~/eesim/Legionnaires data/2016Leg.csv")[,c(2,3,24)]
leg <- data.frame(year = c(leg1$MMWR.Year, leg2$MMWR.Year, leg3$MMWR.Year), week = c(leg1$MMWR.Week, leg2$MMWR.Week, leg3$MMWR.Week), cases = c(leg1$Legionellosis..Current.week, leg2$Legionellosis..Current.week, leg3$Legionellosis..Current.week))
plot(leg$cases, xlab = "Week", ylab = "Number of Cases", main = "Legionnaire's Disease 2014-2016")
```

##Scraping the data

```{r, cache=TRUE}
library(rvest)
library(purrr)
library(dplyr)
library(stringr)
library(lubridate)
library(tidyr)
library(ggplot2)

## For 2017

i <- str_pad(1:14, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_2017.asp?mmwr_year=2017&mmwr_week=", as.character(.x), "&mmwr_table=2J&request=Submit&mmwr_location=", sep=""))
html_2017 <- url %>% map(~read_html(.x))

week_end_date <- html_2017 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

nodes_midatlantic <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)'))
madat <- nodes_midatlantic %>% map(~html_text(.x))
as.numeric(madat)
checkma <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x))

nodes_nyc <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)'))
nycdat <- nodes_nyc %>% map(~html_text(.x))
as.numeric(nycdat)
checknyc <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x))


nodes_pa <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)'))
padat <- nodes_pa %>% map(~html_text(.x))
as.numeric(padat)
checkpa <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x))

leg_cases_2017 <- data_frame(week_end_date = as.character(week_end_date),
                        midatlantic = as.numeric(madat),
                        nyc = as.numeric(nycdat),
                        penn = as.numeric(padat), 
                        checkma = as.character(checkma),
                        checknyc=as.character(checknyc), 
                        checkpa=as.character(checkpa)) %>% 
  mutate(week_end_date = mdy(week_end_date))

## For 2016

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_2016.asp?mmwr_year=2016&mmwr_week=", as.character(.x), "&mmwr_table=2G&request=Submit&mmwr_location=", sep=""))
html_2016 <- url %>% map(~read_html(.x))

week_end_date <- html_2016 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

nodes_midatlantic <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)'))
madat <- nodes_midatlantic %>% map(~html_text(.x))
as.numeric(madat)
checkma <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>%  map(~html_text(.x)) %>% map(~str_trim(.x))

nodes_nyc <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)'))
nycdat <- nodes_nyc %>% map(~html_text(.x))
checknyc <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>%  map(~html_text(.x)) %>% map(~str_trim(.x))
as.numeric(nycdat)

nodes_pa <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)'))
padat <- nodes_pa %>% map(~html_text(.x))
checkpa <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>%  map(~html_text(.x)) %>% map(~str_trim(.x))
as.numeric(padat)

leg_cases_2016 <- data_frame(week_end_date = as.character(week_end_date),
                        midatlantic = as.numeric(madat),
                        nyc = as.numeric(nycdat),
                        penn = as.numeric(padat),
                        checkma = as.character(checkma),
                        checknyc=as.character(checknyc), 
                        checkpa=as.character(checkpa)) %>% 
  mutate(week_end_date = mdy(week_end_date))

## For 2015

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_2015.asp?mmwr_year=2015&mmwr_week=", as.character(.x), "&mmwr_table=2G&request=Submit&mmwr_location=", sep=""))
html_2015 <- url %>% map(~read_html(.x))

week_end_date <- html_2015 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()



leg_cases_2015 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2014

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2014&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2014 <- url %>% map(~read_html(.x))

week_end_date <- html_2014 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()



leg_cases_2014 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##2013

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2013&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2013 <- url %>% map(~read_html(.x))

week_end_date <- html_2013 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2013 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2012

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2012&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2012 <- url %>% map(~read_html(.x))

week_end_date <- html_2012 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2012 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2011

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2011&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2011 <- url %>% map(~read_html(.x))

week_end_date <- html_2011 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2011 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2010

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2010&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2010 <- url %>% map(~read_html(.x))

week_end_date <- html_2010 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2010 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2009

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2009&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2009 <- url %>% map(~read_html(.x))

week_end_date <- html_2009 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2009 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2008

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2008&mmwr_week=", as.character(.x), "&mmwr_table=2C&request=Submit&mmwr_location=", sep=""))
html_2008 <- url %>% map(~read_html(.x))

week_end_date <- html_2008 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2008 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2007

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2007&mmwr_week=", as.character(.x), "&mmwr_table=2C&request=Submit&mmwr_location=", sep=""))
html_2007 <- url %>% map(~read_html(.x))

week_end_date <- html_2007 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2007 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2006

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2006&mmwr_week=", as.character(.x), "&mmwr_table=2C&request=Submit&mmwr_location=", sep=""))
html_2006 <- url %>% map(~read_html(.x))

week_end_date <- html_2006 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2006 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))


# Putting three years together

leg_cases <- bind_rows(leg_cases_2006, leg_cases_2007, leg_cases_2008, leg_cases_2009, leg_cases_2010, leg_cases_2011, leg_cases_2012, leg_cases_2013, leg_cases_2014, leg_cases_2015, leg_cases_2016, leg_cases_2017)

leg_cases[,1:4] %>% 
  gather(key = location, value = cases, - week_end_date) %>% 
  ggplot(aes(x = week_end_date, y = cases, color = location)) + 
  #geom_point() + 
  geom_line() + 
  theme_classic() + 
  theme(legend.position = "top")

```

We can pull the trend from this data:

```{r}
custom
```

### Simulated Data with Similar Trend 

Many epidemiologic data sets are of a sensitive nature and not publicly available.  We can use eesim to simulate data with a similar seasonal trend to fit and assess models.  

```{r, echo=F}
#Question: does exposure need to have trend or is it enough to just make outcome look like real data?
exposure <- continuous_exposure(n=1001, mu = 65, sd = 3, trend = "no trend", amp=.4)
#Make this into weekly data instead of daily.
exposuremat <- matrix(data=exposure$x, ncol = 7, nrow=143, byrow=T)
exposurex <- apply(exposuremat, 1, mean)
newdate <- seq.int(from=exposure$date[1], to=exposure$date[1001], by=7)
weeklyexp <- data.frame(date=newdate, x=exposurex)
plot(weeklyexp, main = "Plot of Exposure values")
outcome <- sim_outcome(weeklyexp, average_outcome = 10, trend = "cos1linear")
plot(outcome$outcome)

#Try with eesim function
leg <- eesim(n_reps=1, n=800, central = 65, sd = 3, exposure_type = "continuous", exposure_trend = "no trend", exposure_amp=.6,average_outcome = 10, outcome_trend = "cos1linear", outcome_amp = .6, rr= 1.02, model = "spline", df_year = 4)
plot(leg[[3]]$outcome)
```
