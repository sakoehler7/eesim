---
title: "Outstanding Title"
author: "Sarah Koehler"
date: "February 21, 2017"
bibliography: mybibfile.bib
output:
  pdf_document: default
  html_document: default
---

```{r echo = FALSE}
# knitr::opts_chunk$set(eval = FALSE)
```


# Introduction

Simulation studies are important in environmental epidemiology research on air pollution, temperature, and other exposures. For example, simulated data can be used to test new statistical models and perform power analyses. Two current challenges of simulating time series data for epidemiology studies are (1) methods for simulating are inconsistent, making it difficult to compare results from different studies, and (2) developing the code to simulate environmental time series for these types of studies can be time consuming. We introduce `eesim`, an open-source software package in R that offers a solution to these challenges.

Simulated data has been used in a number of environmental epidemiology studies on various kinds of exposures and outcomes. [@Armstrong2014] used a simulation study to investigate short-term mortality displacement following heat waves. [@Bateson1999], [@Bateson2001], and [@Peng2006] used simulated data with confounding seasonal trends to compare experimental designs and model choice. [@Strickland2015], [@Gryparis2009], and [@Butland2013] investigated spatial misalignment and geographic heterogeneity of exposures using simulated data. [@Roberts2006] used a simulation study to test the reliability of using AIC to determine the shape of the relationship between particulate matter and mortality. [@Bobb2015] used simulation to assess the performance of a proposed method for estimating the health effects of multi-pollutant exposures called Bayesian kernel machine regression (BKMR). 

Here, we present an R package that automates simulation of environmental time series for such studies, offering both sensible defaults for each stage of the simulation process and also the option to customize any of the simulation steps while using defaults for any steps that do not require customization. There are a few important advantages to having an open-source software package that can simulate this type of environmental time series for simulation studies. This package offers several methods of simulating time series so researchers can check if study results are robust to the data simulation method [@Alfons2010]. This software also allows for consistency and comparison of data simulation across studies and will save researchers time and effort in developing study-specific code. 

This package can be used to aid simulation studies to explore environmental epidemiology models relating acute health outcomes and daily environmental exposures; it can also be used to estimate the power of studies when planning or proposing future research.

# Simulating Data and Testing Models

Simulation studies can be used to assess different models and modeling choices. This way of assessing models can be particularly useful for complex statistical methods, for which assessing performance metrics can often prove difficult [@Alfons2010]. The `eesim` package allows you to simulate time series of environmental health data and perform simulation-based power analyses and other measures of model performance. The package includes four main parts: 

1. Generation of exposure data; 
2. Generation of outcome data;
3. Fitting models to simulated data; and 
4. Evaluating model performance on simulated data.

The user has the option to customize different aspects of the simulation at each of these steps.

The main function of this package is the `eesim` function. You can use the `eesim` function to conduct all four steps of the simulation process outlined above at once. The `eesim` function requires several arguments, both numeric and character, including the desired number of repetitions of the simulation, the sample size for each repetiton, the type of exposure values (binary or continous), the expected average value of the response variable, the relative risk, and the type of model desired. The user has the option to input more arguments specifying trends or custom functions for the exposure, the outcome, or both.

The `eesim` function returns a list with two elements. The first element gives simulation-specific results: the estimated effect size, standard error, t- and p-values, and upper and lower 95% confidence bounds when a model was applied to each set of simulated data. The second element gives some measures of model assessment, assessed over all simulations, including the mean effect size and relative risk estimates across simulations.

[insert equation here?]

For example, you can use the following call to (1) generate 3 repetitions of 100 observations of a continuous exposure with mean 50 and standard deviation 5, with a seasonal trend in expected value; (2) generate 10 associated outcome values, where the outcome has an average value of 20 and a relative risk of 1.10 per one-unit increase in the exposure; (3) fit a generalized linear model that controls for long-term and seasonal trends with a natural cubic spline with 2 degrees of freedom per year; and (4) evaluate the performace of that model on the simulated data:

```{r}
library(eesim)
eesim(n_reps = 3, n = 100, central = 50, sd = 5, outcome_amp = .6, exposure_type = "continuous", outcome_trend = "cos1", average_outcome = 20, rr = 1.10, model = "spline", df_year = 2)
```

The above output gives the estimated effect sizes for each of the three repetitions along with their standard errors, test statistics, p-values, and confidence intervals. It also summarizes the outcomes of all three repetitions with a mean estimated beta (which equals the log of the estimated relative risk), estimated relative risk, the variance of the estimated betas, and the mean variance of the individual betas.  

The `eesim` output also gives the relative parameter estimate bias, according to the following equation  from [@Beaujean2014], given $\theta_{H}$ (true value of the parameter, as set when creating the simulated data) and $\hat{\theta}$ (value of the parameter estimated from applying a model to the simulated data): 

\begin{equation}
\theta_{bias} = \frac{\hat{\theta} - \theta_{H}}{\theta_{H}}
\end{equation}

Finally, the `eesim` output gives the coverage and power of the model.

# Power Analysis

Simulation studies can be used to determine effective sample size or power when planning or proposing future research studies. This method can be particularly useful in cases where modeling of the study data will be particularly complex and when the strong assumptions of classical, analytical power analysis are questionable [@Bellan2015; @Johnson2015; @Burton2009; @Alfons2010; @Beaujean2014; @Schoemann2014]. Simulation studies can often be used to generate power analyses under a more realistic set of assumptions [@Burton2009; @Beaujean2014].

In `eesim`, the function `power_calc` can be used to investigate the effects of various sample sizes or relative risks on power. This function requires arguments including the parameter to be varied (sample size or relative risk), the desired values of that parameter, and lists of the same arguments as used in the `eesim` function. The `power_calc` function outputs a table of the values of the varied parameter along with their corresponding power. 
Here is an example of using `power_calc` to test power for different sample sizes:

```{r}
#Power_calc works except the casecrossover option
```

The `power_calc` function will also return a plot if `plot=TRUE` is specified. 

## Legionnaire's Example

As a case study, we give an example of conducting a power analysis for a planned study of the relationship between Legionnaires' disease (LD) and extreme precipitation in a community. 

[Description of LD]
The bacteria that causes LD, *Legionella*, is often present in ... . 
[Where Lp live-- water systems, systems for A/C, ...]
[What Lp need to grow-- protozoa (must grow inside them?), temperature conditions, water, water temperature?]
[What Lp need to spread-- survival on aerosols, lower UV, enough wind to spread aerosols but not to break up aerosols, high relative humidity]
The incubation period for LD is 2--10 days (this is relevant for the time between dispersal of Lp on aerosols and case onset) [@Halsby2014] [also could reference Campese et al. 2011, Farnham et al. 2014, Graham et al. 2011, Whiley et al. 2014, Phin et al. 2014, Brandsema et al. 2014, Dunn et al. 2012, Fisman et al. 2005, Halsby et al. 2013].
[Destinction between community-acquired LD and other LD cases; sporadic vs. epidemic]
Based on previous studies, approximately 2--6% of LD cases are outbreak-associated, rather than sporadic [Campese et al. 2011, Graham et al. 2011, Fisman et al. 2005, Halsby et al. 2013, Phin et al. 2014].
Community counts of sporadic, community-acquired LD cases have been found to display a strong seasonal pattern, with most cases in summer to early fall [@Halsby2014; Campese et al. 2011; Falkinham et al. 2015; Farnham et al. 2014; Phin et al. 2014; Brandsema et al. 2014]. This seasonal trend may stem in part from seasonal variaition in weather factors, but may also be related to other seasonally-varying factors. Counts of LD cases have also shown a strong long-term trend in many locations, including in England and Wales between 1993 and 2008 [@Halsby2014], in France between 1998 and 2008 [Campese et al. 2011], and in the United States between 2000 and 2011 [Falkinham et al. 2015], ... . This long-term trend may in part reflect a growing improvement in reporting and testing [?] of potential cases [ref]; in fact, one study in Australia notes that the total incidence of LD cases might be a factor of 20 higher than the number of reported cases because of severe underreporting [Whiley et al. 2014]. 

[Why we think LD might be linked with weather] 
[Theoretical reasons]
Weather could affect risk of LD by affecting either the growth or the spread, via aerosol dispersion [?], of the *Legionella* bacteria that causes the disease. [Why weather factor might affect growth of Lp] [Temperature could affect growth of Lp, including through a chain that increases growth of what protozoa eat, since Lp need to grow in protozoa?] A number of weather-related factors, including higher relative humidity and lower exposure to sunlight [?], might aid in survival of *Legionella* on aerosols [check Berendt 1980, Survival of Legionella pneumophila in aerosols...; Hambleton et al. 1983, Susceptibility of Lp to ultraviolet radiation; check for anything more current about survival of Lp on aerosols]
[Evidenced on sporadic cases from epi studies]
Several studies have investigated the association between weather conditions and daily counts of community-acquired LD cases using time series models. Many of these have found an increased risk of community-acquired LD following certain weather conditions; weather variables implicated include rainfall, wind speed, sunlight, relative humidity. For example, a study of community-acquired LD and weather in England and Wales found increased risk of LD associated with higher temperatures (at lags of 1--9 weeks; estimated odds ratio for 95th percentile versus 75th percentile temperature of 3.91), higher relative humidity (at lags of 2--10 days; estimated odds ratio for 75th versus 50th percentile relative humidity of 1.52), and higher rainfall (at lags of 2--10 days; estimated odds ratio for 75th versus 50th percentile rainfall of 1.78) [@Halsby2014]. A study of sporadic LD cases in the Netherlands between 2003 and 2011 found increased risk associated with warm temperature (4-week mean) and increased rainfall (2-week duration and intensity) [Brandsema et al. 2014]. A study in Taiwan between 1995 and 2011 found an increase in LD cases associated with increased temperature (lag day 10-11) and increased precipitation (lag day 11), with an increased risk of LD cases of 2.6 associated with heavy versus no rainfall eleven days prior [Nai-Tzu et al. 2014]. A study of LD cases in the greater Philadelphia metropolitan area between 1995 and 2003 found increased risk of LD following about eight days following precipitation (compared to no precipitation) as well as increased risk associated with higher relative humidity and higher temperature and decreased risk associated with a higher wind speed (at a similar lag?) [double-check. Fisman et al. 2005].
[Evidence on outbreak cases from epi studies]
The risk of outbreaks of LD might also be related to weather conditions, including extreme precipitation (e.g., [check Hoyle et al. 1985 Legionnaires' disease: seeking a wider source; Thacker et al. 1978, An outbreak in 1965 of severe respiratory illness caused by ...]).

[Why power might be an issue in a study of LD and weather] 
While the epidemiological estimates of the association between LD and weather variables could help in designing strategies to prevent cases of the disease or identify periods of heightened risk, the power to do such an analysis may be low in many communities because LD is typically a fairly rare disease. For example, a study of all sporadic community-acquired LD cases throughout England and Wales between 1993 and 2008 included only 1,676 cases after excluding cases that were possible travel-acquired and other data quality-related exclusions [@Halsby2014]. Several studies have used time series [Dunn et al. 2012] or case-crossover [@Halsby2014, Nai-Tzu et al. 2014, Fisman et al. 2005] designs to investigate the association between weather variables and community-wide risk of LD. These, however, have mostly been conducted on very large study populations (e.g., England and Wales[@Halsby2014]; Netherlands [Brandsema et al. 2014]; Taiwan [Nai-Tzu et al. 2014]). Even in these large populations, associations with some weather variables were suggestive but not statistically significant (e.g., for windspeed and UV in England and Wales; @Halsby2014). One study was conducting in a smaller population (the greater Philadelphia metropolitan area; Fisman et al. 2005). Some of these studies have controlled for season [@Halsby2014; Brandsema et al. 2014, Nai-Tzu et al. 2014, Fisman et al. 2005] while some have not [?].  

Since it is unclear if the relationship between LD risk and weather variables is linear, many of these studies have investigated either categorical versions of the weather variables [e.g., Brandsema et al. 2014, Nai-Tzu et al. 2014] or estimated risks at two percentiles along the weather variable's full distribution (e.g., @Halsby2014).

### Actual Data from the CDC

We can perform power analyses on real data to determine whether we have a large enough sample size, relative risk, or average outcome value to provide sufficient power for testing hypotheses.  Presented here is weekly data from the CDC on mortality related to Legionnaire's disease (citation?). We focus on data from New York City, Pennsylvania, and the Midatlantic region from 2006 through 2017.

```{r, echo=FALSE}
#I used the variable "Legionellosis, Current week" so hopefully that's right
leg1 <- read.csv("~/eesim/Legionnaires data/2014Leg.csv")[,c(2,3,24)]
leg2 <- read.csv("~/eesim/Legionnaires data/2015Leg.csv")[,c(2,3,24)]
leg3 <- read.csv("~/eesim/Legionnaires data/2016Leg.csv")[,c(2,3,24)]
leg <- data.frame(year = c(leg1$MMWR.Year, leg2$MMWR.Year, leg3$MMWR.Year), week = c(leg1$MMWR.Week, leg2$MMWR.Week, leg3$MMWR.Week), cases = c(leg1$Legionellosis..Current.week, leg2$Legionellosis..Current.week, leg3$Legionellosis..Current.week))
plot(leg$cases, xlab = "Week", ylab = "Number of Cases", main = "Legionnaire's Disease 2014-2016")
```

```{r, echo=F, warning=F, message=F}
#Scraping the data from CDC

library(rvest)
library(purrr)
library(dplyr)
library(stringr)
library(lubridate)
library(tidyr)
library(ggplot2)

## For 2017

i <- str_pad(1:14, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_2017.asp?mmwr_year=2017&mmwr_week=", as.character(.x), "&mmwr_table=2J&request=Submit&mmwr_location=", sep=""))
html_2017 <- url %>% map(~read_html(.x))

week_end_date <- html_2017 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

nodes_midatlantic <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)'))
madat <- nodes_midatlantic %>% map(~html_text(.x))
as.numeric(madat)
checkma <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x))

nodes_nyc <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)'))
nycdat <- nodes_nyc %>% map(~html_text(.x))
as.numeric(nycdat)
checknyc <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x))


nodes_pa <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)'))
padat <- nodes_pa %>% map(~html_text(.x))
as.numeric(padat)
checkpa <- html_2017 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x))

leg_cases_2017 <- data_frame(week_end_date = as.character(week_end_date),
                        midatlantic = as.numeric(madat),
                        nyc = as.numeric(nycdat),
                        penn = as.numeric(padat), 
                        checkma = as.character(checkma),
                        checknyc=as.character(checknyc), 
                        checkpa=as.character(checkpa)) %>% 
  mutate(week_end_date = mdy(week_end_date))

## For 2016

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_2016.asp?mmwr_year=2016&mmwr_week=", as.character(.x), "&mmwr_table=2G&request=Submit&mmwr_location=", sep=""))
html_2016 <- url %>% map(~read_html(.x))

week_end_date <- html_2016 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

nodes_midatlantic <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)'))
madat <- nodes_midatlantic %>% map(~html_text(.x))
as.numeric(madat)
checkma <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>%  map(~html_text(.x)) %>% map(~str_trim(.x))

nodes_nyc <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)'))
nycdat <- nodes_nyc %>% map(~html_text(.x))
checknyc <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>%  map(~html_text(.x)) %>% map(~str_trim(.x))
as.numeric(nycdat)

nodes_pa <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)'))
padat <- nodes_pa %>% map(~html_text(.x))
checkpa <- html_2016 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>%  map(~html_text(.x)) %>% map(~str_trim(.x))
as.numeric(padat)

leg_cases_2016 <- data_frame(week_end_date = as.character(week_end_date),
                        midatlantic = as.numeric(madat),
                        nyc = as.numeric(nycdat),
                        penn = as.numeric(padat),
                        checkma = as.character(checkma),
                        checknyc=as.character(checknyc), 
                        checkpa=as.character(checkpa)) %>% 
  mutate(week_end_date = mdy(week_end_date))

## For 2015

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_2015.asp?mmwr_year=2015&mmwr_week=", as.character(.x), "&mmwr_table=2G&request=Submit&mmwr_location=", sep=""))
html_2015 <- url %>% map(~read_html(.x))

week_end_date <- html_2015 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2015 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()



leg_cases_2015 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2014

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2014&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2014 <- url %>% map(~read_html(.x))

week_end_date <- html_2014 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2014 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()



leg_cases_2014 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##2013

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2013&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2013 <- url %>% map(~read_html(.x))

week_end_date <- html_2013 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2013 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2013 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2012

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2012&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2012 <- url %>% map(~read_html(.x))

week_end_date <- html_2012 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2012 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2012 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2011

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2011&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2011 <- url %>% map(~read_html(.x))

week_end_date <- html_2011 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2011 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2011 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2010

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2010&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2010 <- url %>% map(~read_html(.x))

week_end_date <- html_2010 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2010 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2010 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2009

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2009&mmwr_week=", as.character(.x), "&mmwr_table=2F&request=Submit&mmwr_location=", sep=""))
html_2009 <- url %>% map(~read_html(.x))

week_end_date <- html_2009 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(12) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(15) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(2)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2009 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2009 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2008

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2008&mmwr_week=", as.character(.x), "&mmwr_table=2C&request=Submit&mmwr_location=", sep=""))
html_2008 <- url %>% map(~read_html(.x))

week_end_date <- html_2008 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2008 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2008 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2007

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2007&mmwr_week=", as.character(.x), "&mmwr_table=2C&request=Submit&mmwr_location=", sep=""))
html_2007 <- url %>% map(~read_html(.x))

week_end_date <- html_2007 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2007 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2007 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))

##For 2006

i <- str_pad(1:52, pad = "0", width = 2)
url <- i %>% map(~paste("https://wonder.cdc.gov/mmwr/mmwr_1995_2014.asp?mmwr_year=2006&mmwr_week=", as.character(.x), "&mmwr_table=2C&request=Submit&mmwr_location=", sep=""))
html_2006 <- url %>% map(~read_html(.x))

week_end_date <- html_2006 %>% 
  map(~html_nodes(.x, 'tr:nth-child(1) td:nth-child(1)')) %>% 
  map(~html_text(.x)) %>% 
  map(~ str_extract(.x[1], "week ending .+ \\(")) %>% 
  map(~ str_replace(.x[1], "week ending", "")) %>% 
  map(~ str_replace(.x[1], "\\(", "")) %>% 
  map(~ str_trim(.x[1]))

madat <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkma <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(13) td:nth-child(1)')) %>% map(~html_text(.x)) %>% map(~str_trim(.x)) %>% as.character()

nycdat <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checknyc <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(16) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

padat <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(12)')) %>% map(~html_text(.x)) %>% as.numeric()
checkpa <- html_2006 %>% map(~html_nodes(.x, 'tr:nth-child(17) td:nth-child(1)')) %>% map(~html_text(.x))%>% map(~str_trim(.x)) %>% as.character()

leg_cases_2006 <- data_frame(week_end_date = as.character(week_end_date),
                             midatlantic = madat,
                             nyc = nycdat,
                             penn = padat, 
                             checkma = checkma,
                             checknyc = checknyc,
                             checkpa = checkpa) %>% 
  mutate(week_end_date = mdy(week_end_date))


# Putting all years together

leg_cases <- bind_rows(leg_cases_2006, leg_cases_2007, leg_cases_2008, leg_cases_2009, leg_cases_2010, leg_cases_2011, leg_cases_2012, leg_cases_2013, leg_cases_2014, leg_cases_2015, leg_cases_2016, leg_cases_2017)

leg_cases[,1:4] %>% 
  gather(key = location, value = cases, - week_end_date) %>% 
  ggplot(aes(x = week_end_date, y = cases, color = location)) + 
  #geom_point() + 
  geom_line() + 
  theme_classic() + 
  theme(legend.position = "top")

save(leg_cases, file="data/leg_cases.rda")

```

```{r}
#Checking for anomalies:
leg_cases[which(leg_cases$checkma != "MID. ATLANTIC"),]
leg_cases[which(leg_cases$checknyc != "N.Y. City"),]
leg_cases[which(leg_cases$checkpa != "Pa."),]

#Row 48 is the only row with different states. 569 and 574 have NA in every column.
```

```{r}
#Power analysis using eesim

```

We can pull the trend from this data:

```{r}
custom
```

### Simulated Data with Similar Trend 

Many epidemiologic data sets are of a sensitive nature and not publicly available.  We can use eesim to simulate data with a similar seasonal trend to fit and assess models.  

```{r, echo=F}
#Means of real data:
map(leg_cases[,2:4], mean, na.rm=T)
#(ma=14.633, nyc=4.69, pa=5.314)
exposure <- continuous_exposure(n=1001, mu = 65, sd = 5, trend = "cos1", amp=.4)
#Make this into weekly data instead of daily.
x <- seq.int(from=1, to=1001, by=7)
weeklyexp <- exposure[x,]
plot(weeklyexp, main = "Plot of Exposure values")
outcome <- sim_outcome(weeklyexp, average_outcome = 4.69, trend = "no trend")
plot(outcome$outcome)

```
