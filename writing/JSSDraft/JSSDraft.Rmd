---
author:
  - name: Sarah Koehler
    affiliation: Colorado State University
    address: >
      Lake Street
      Fort Collins, CO
    email: sakoehler7@gmail.com
  - name: G. Brooke Anderson
    affiliation: Colorado State University
    address: >
      Lake Street
      Fort Collins, CO
    email: brooke.anderson@colostate.edu
title:
  formatted: "\\pkg{eesim}: An R Package to Simulate Environmental Epidemiology Time Series for Simulation Studies and Power Analyses"
  # If you use tex in the formatted title, also supply version without
  plain:     "eesim: An R Package to Simulate Environmental Epidemiology Time Series for Simulation Studies and Power Analyses"
  # For running headers, if needed
  short:     "\\pkg{eesim}: Simulations for Environmental Epidemiology"
abstract: >
  Simulation studies are important in environmental epidemiology research on air pollution, temperature, and other exposures. For example, studies have simulated time series of environmental exposure and health outcome data to compare time series and case-crossover methods; explore models to test for mortality-displacement; investigate the impacts of measurement error and spatial misalignment of exposure and outcome measurements; and search for confounding by other time-varying covariates. 
  
  Developing the code to simulate environmental time series for these types of studies can be time consuming, and simulation methods have varied across previous simulation studies, complicating the comparison of results across different studies. Here, we present an R package that automates simulation of environmental time series for such simulations, offering both sensible defaults for each stage of the simulation process and also the option to customize any of the simulation steps while using defaults for any steps that do not require customization. This packge can be used to aid simulation studies to explore environmental epidemiology models relating acute health outcomes and daily environmental exposures; it can also be used to estimate the power of studies when planning or proposing future research.
keywords:
  # at least one keyword must be supplied
  formatted: [R, environmental epidemiology, simulation studies, power analysis, air pollution]
  plain:     [R, environmental epidemiology, simulation studies, power analysis, air pollution]
preamble: >
  \usepackage{amsmath}
output:
  rticles::jss_article:
    citation_package: natbib
bibliography: mybibfile.bib
---

# Introduction

## Environmental time series studies and why they're important

## Using simulated time series for power analysis

Simulation studies can be used to determine effective sample size or power when planning or proposing future research studies. This method can be particularly useful in cases where modeling of the study data will be particularly complex and when the strong assumptions of classical, analytical power analysis are questionable \citep{Bellan2015, Johnson2015, Burton2009, Alfons2010, Beaujean2014}. Simulation studies can often be used to generate power analyses under a more realistic set of assumptions \cite{Burton2009, Beaujean2014}.

For example, \citet{Bellan2015} used a simulation study to determine the power and statistical validity of two potential Ebola vaccine trials, a randomized controlled trial and a stepped-wedge cluster trial. Simulation was useful in this case because the trial would be conducting in a population with clustering by geographical district and with a temporally changing hazard of Ebola infection over the trial period \citep{Bellan2015}.

\citet{Johnson2015} give an example of using simulation for a power analysis of a study of numbers of ticks on grouse chicks in a study design with multi-level clustering of the study population, both by geographic area and, within that, by brood.

\citet{Burton2009} used simulation to investigate the power of case-control studies of genetic associations for chronic diseases.

A number of R packages have been created to do power analyses through simulations for a variety of purposes and contexts, including for genetic association studies \citep{Gaye2015}, microbiome studies \citep{Kelly2015}, network data \citep{Handcock2008}, survey statistics \citep{Alfons2010}, ... . More general-purpose R packages also exist for simulations for power analyses, including packages for power analyses for generalized linear mixed models \cite{Green2016}, ... . 

## Using simulated time series to test modeling questions

Simulation studies can also be used to assess different models and modeling choices. This way of assessing models can be particularly useful for complex statistical methods, which can often be very hard to assess performance metrics of using analytical methods \citep{Alfons2010}.

Several R packages exist that simulate data to allow model evaluation in a variety of domains. For example, \code{ss3sim} allows the simulation of fisheries stock assessment for use in evaluating methods in fishery stock assessments \citep{Anderson2014}.

## Challenges in creating simulated time series

For many environmental time series studies, including those investigating air pollution and temperature, both exposures and outcomes can have complex seasonal and longer-term patterns over the study period. For example, air pollution concentrations can change seasonally, both because of changes in emission patterns and meteorological patterns (for example, winter inversion layers can cause a build-up of particulate matter in the winter, while high temperatures in the summer can accelate ozone formation from precursors); air pollution concentrations can also change over years, especially with evolving Clean Air policies.

Exposures, outcomes, and their relationship with each other can all have complex patterns that could cause problems in epidemiological studies. For example, \citet{Armstrong2014} explain how autocorrelation in temperature data (e.g., days right after a very severe heat wave are likely to be hotter than days right after a milder heat wave) can introduce spurious results in a model testing for evidence of short-term mortality displacement following heat waves.

There are a few important advantages to having an open-source software package that can simulate this type of environmental time series for simulation studies. First, current methods of simulating environmental time series, to use to assess modeling choices, vary across different studies. While, ideally, results from a simulation study would be robust to different choices in how to simulate the data used in the study, this may not always be the case; if so, results across studies using different methods of simulating data would not be comparable \citep{Alfons2010}. This package offers a tool that both allows different research to simulate environmental time series for simulation studies in a consistent way, it also offers several methods of simulating time series, and so allows researchers to check if simulation results are sensitive to the method of simulating study data. Tools for consistency across studies have helped in the progress of environmental epidemiology research; for example, the public availability of the NMMAPs dataset--which included air pollution, weather, and mortality counts in over 100 US communities for 14 years-- allowed researchers around the world to explore hypotheses and investigate health effects of air pollution and temperature using the same data, and so differences in results could be traced to methodological differences rather than random differences in environmental datasets. [We could add some on the usefulness of (1) reproducible studies and (2) open source software for scientific studies here.]

Further, developing the code to simulate environmental time series in an appropriate way can be time consuming. While researchers often need to customize certain parts of a simulation, to test a particular research question, often most of the simulation can be performed in a way that is generalizable across most other environmental time series studies. Therefore, by providing simulation tools with reasonable defaults, as well as room to customize at each step of the simulation, this package can make environmental epidemiolgoy simulation studies much more efficient and also make simulation a reasonable alternative for determining expected power when planning and proposing future studies.

# Examples of studies that simulated environmental time series

## Mortality displacement

\citet{Armstrong2014} used a simulation study to investigate whether evidence of short-term mortality displacement following heat waves was a result of model artifacts. To do this, they aimed to simulate a time series of heat wave (binary) effects with heat wave effects, none of which were caused by short-term mortality displacement. They then showed that, when they fit the model from the previous study to this simulated dataset, the model generated results suggestive of short-term mortality displacement, and less displacement with more severe heat waves than less severe heat waves, which were similar to the findings of the study they were assessing. Overall, this analysis suggested that the earlier study's results might have been an artifact of the modeling approach they used, and so their results could be consistent with a hypothesis of no mortality displacement.

To do this simulation, which required simulating a time series with a heat wave effect on mortality, but no short-term displacement to explain some of that excess mortality, \citet{Armstrong2014} started with a real dataset of daily temperature and mortality counts. For this, they used the NMMAPS dataset (1987--2000) from Atlanta, GA, which was one of the datasets used in the original study. They fit a model of expected log mortality count for this real data regressed on daily (lag 0) temperature and a smooth function of time (to capture seasonal and long-term variation). They then predicted from this model for the days in their simulation, to generate a smoothed estimate of expected daily mortality on each day (note: this daily expected count is a function of observed temperature over the study period; it sounds like they used observed data directly for the exposure time series). They then drew simulated daily mortality counts from a Poisson distribution with $\lambda$ equal to this daily expected mean mortality for each day in the simulation period. [Code they used for this simulation analysis is available as an online supplement.]

## Comparing case-crossover and time series

## Investigating confounding

## Exploring spatial misalignment between exposure and outcome measurements

# Basic overview of package

[Table / Figure of functions included and simulation process]

A time series of simulated count outcome data with Poisson random noise can be simulated using the following model \citep{Johnson2015}:

\begin{equation}
\eta_t = \beta_0 + \sum_{m=1}^{p}\beta_{m}X_{m,t} 
\end{equation}

\begin{equation}
\eta_t = log(\lambda_t)
\end{equation}

\begin{equation}
y_i \sim Pois(\lambda_t)
\end{equation}

\noindent which is a Generalized Linear Model where $\eta_t$ is the linear predictor and a log link is used.

# Implementing the package

## Simulating time series

## Using simulated time series for power analysis

Running a power analysis requires specifications of effect sizes, baseline counts of health outcomes, and shape of seasonal trends in exposures and outcomes. These values can be specified at realistic values based on previous research \citep{Johnson2015}; if no relevant previous research exists, in some cases a pilot study can be used to determine reasonable values to use for these inputs \citep{Johnson2015}.

## Using simulated time series to test modeling questions

## Evaluating simulations based on these time series

A number of different metrics are used to evaluate the results of simulation studies. These include: 

* False positive rate / type I error rate (percent of time significant effect is detected-- i.e., null hypothesis is rejected-- when there is not a true effect) \citep{Bellan2015, Johnson2015}
* Power / Statistical power to detect a true effect of a certain size / empirical power (percent of simulations in which a true effect of a certain size is identified with a p-value of 0.05 or lower; i.e., probability of rejecting the null hypothesis when the null hypothesis is false) \citep{Bellan2015, Johnson2015, Gaye2015, Green2016, Beaujean2014}
* Precision of effect estimate (average confidence interval width over all simulations; some studies give average half-width) \citep{Johnson2015, Beaujean2014}
* Coverage / 95% confidence inverval coverage (percent of 95% confidence intervals from simulations that include the true effect size) \citep{Johnson2015, Beaujean2014}
* Bias in effect estimate \citep{Johnson2015}
* Margin of error [?] \citep{Johnson2015}
* Sample size required to detect a certain effect size \citep{Burton2009, Gaye2015, Green2016, Beaujean2014}
* Time to achieve required number of cases \citep{Burton2009}
* Power curve \citep{Beaujean2014}
* Accuracy curve \citep{Beaujean2014}

\citet{Beaujean2014} gives the following equation for calculating relative parameter estimate bias, given $\theta_{H}$ (true value of the parameter, as set when creating the simulated data) and $\hat{\theta}$ (value of the parameter estimated from applying a model to the simulated data): 

\begin{equation}
\theta_{bias} = \frac{\hat{\theta} - \theta_{H}}{\theta_{H}}
\end{equation}

\citet{Beaujean2014} gives the following equation for calculating relative standard error bias, given $\sigma_{\hat{\theta}}$ (the standard deviation of the parameter estimations across the simulations) and $\hat{\sigma_{\theta}}$ (the average of the standard errors estimated for the simultations):

\begin{equation}
\sigma_{bias} = \frac{\hat{\sigma_{\theta}} - \sigma_{\hat{\theta}}}{\sigma_{\hat{\theta}}}
\end{equation}

## Customizing simulations

While R packages always offer the opportunity for a user to alter the original code to create customized solutions, this process can require extensive skill in R programming for anything but fairly straightforward functions. Here, we provide the opportunity at every step of the simulation process for a user to input custom R functions, from simple to complex, to be run through our functions, without requiring changes to the function code provided by the package. 

For each of the customization options, we have provided the input and output rules required for a custom function to use for that step. A custom function can include any code, and implement any functionality, as long as it adheres to these rules for the input it takes and output it produces. Further, through using R's "dots" functionality, custom functions can include inputs other than those specified by our interface rules, as long as the custom function inputs, at a minimum, the inputs required by the interface rules. 

# Discussion

## Limitations

We currently do not include overdispersion when simulating health outcome counts. \citet{Johnson2015} discusses why this might be problematic and suggests some methods for incorporating overdispersion in a simulation in cases where count outcome data is expected to include overdispersion. They suggest that the following model can be used to generate the expected outcome count with overdispersion-- modeling the linear predictor as: 

\begin{equation}
\eta_t = \beta_0 + \sum_{m=1}^{p}\beta_{m}X_{m,t} + \epsilon_t
\end{equation}

\noindent where $\epsilon_t$ represents the overdispersion and follows a normal distribution: 

\begin{equation}
\epsilon_t \sim N(0, \sigma_{\epsilon}^2)
\end{equation}

In the case of no overdispersion, $\sigma_{\epsilon}^2$ equals 0. In the case of overdispersion, $\sigma_{\epsilon}^2$ will be larger than 0.

# Acknowledgments

# References
